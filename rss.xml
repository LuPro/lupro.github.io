<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>lprod Blog</title><link>https://lprod.dev/rss.xml</link><description>Random ramblings in various projects I work on</description><atom:link href="https://lprod.dev/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 01 Jul 2024 21:38:31 +0000</lastBuildDate><item><title>Touchscreen Corner Gestures</title><link>https://lprod.dev/blog/touch_corner_gestures.html</link><description>Because there aren't enough gestures yet

&lt;html&gt;
&lt;p&gt;After working on a thorough overhaul of the gesture navigation mode of the Plasma Mobile task switcher (see my &lt;a href="https://lprod.dev/blog/plasmo_nav_gestures.html"&gt;previous blog&lt;/a&gt;) I've been thinking about some more things I could do to improve interaction and navigation for Plasma Mobile. As a self-proclaimed gesture connoisseur this obviously means adding more gesture capabilities.&lt;/p&gt;

&lt;p&gt;Now, something that would be really cool is having the ability for setting custom gestures in the screen corners, specifically the lower screen corners. This should very nicely complement the task switcher navigation gesture on the lower border and provide a convenient shortcut to &lt;i&gt;something&lt;/i&gt;, more on that later.&lt;/p&gt;

&lt;p&gt;Ideally for this I want to leverage KWin's gesture capabilities to not have to reinvent the wheel. There is just one tiny problem: KWin doesn't support touch screen corner gestures.&lt;/p&gt;

&lt;h1&gt;Why not?&lt;/h1&gt;

&lt;p&gt;
Ultimately: I don't know. But having now worked on adding them I think I know a likely reason: It's surprisingly hard.&lt;/p&gt;

&lt;p&gt;Before we can continue let's pause for a second to get some terminology out of the way. In KWin's codebase &lt;code&gt;ScreenEdge&lt;/code&gt; (as well as &lt;code&gt;Edge&lt;/code&gt;) refers to classes that store information regarding, well, the edges of a screen. Crucially, this also includes screen &lt;i&gt;corners&lt;/i&gt;, not just the side edges.&lt;/p&gt;

&lt;p&gt;The same screen edge instances are shared between the "hot corner" functionality for mouse input (triggered by moving the mouse cursor into a corner or side edge), as well as touch gestures. The screen edges were however restricted to only listen for touch input when they are actually an edge and &lt;i&gt;not&lt;/i&gt; a corner.&lt;/p&gt;

&lt;p&gt;The screen edges themselves had little reason to do so, but it was restricted that way because corner gestures made two important things a lot more complex:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;GestureRecognizer&lt;/code&gt; which... recognizes gestures (who'd have thought) has a slightly harder time doing its gesture recognizing because corner gestures don't have a strict direction; They should be invokable by a mostly upwards, mostly horizontal or diagonal move - the only relevant part is that the gesture started in the corner. Compare this to the edge gestures which only trigger on orthogonal movement (ie: The bottom edge gesture only triggers on mostly upwards movement)&lt;/li&gt;&lt;li&gt;The creation of the actual "hitbox" of the screen corners, which is especially complicated because some screens have that pesky habit of having a corner radius. Especially phones.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
I want to elaborate a bit on the second part: The previous &lt;code&gt;ScreenEdge&lt;/code&gt; geometry logic was delightfully simple. There was a hardcoded value of 3 logical pixels (= pixels, but scaled by the display scaling factor) of thickness. This applied to the edges making them 3 logical pixels thick and otherwise completely fill their respective screen edge. Corners on the other hand got "the rest" making them a neat 3x3 logical pixels in size. Great for a mouse since you can just throw that into the screen corner and the edges make your cursor properly "find" the exact corner.&lt;/p&gt;

&lt;p&gt;However, this is not quite as usable for touch inputs. A thin edge is no problem, just swipe in from the edge and the first pixels you touch from the touch sensitive screen area will be in the 3 pixels area. The corner however is not as easily hittable with a finger. So it needs to be bigger. But we can't make it a square otherwise it would majorly overlap with on-screen elements like for example the application launcher in the bottom left corner or window close buttons in the top right.&lt;/p&gt;

&lt;h1&gt;What did I do?&lt;/h1&gt;

&lt;p&gt;
Now that's the big question. A big part of my changes were making the wonderfully simple hitbox creation logic much less wonderfully simple.&lt;/p&gt;

&lt;p&gt;The new hitbox logic creates a thin border consisting of "two" rectangles, one horizontal and one vertical, with the same thickness as the normal screen edge geometry (3 logical pixels). Additionally, it allows to set a variable corner radius to allow the screen edge to adapt to screen corner radii.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://lprod.dev/blog/media/touch_corner_gestures.png" alt="Here, have a not very good looking sketch"&gt;&lt;/img&gt;&lt;label class="media-caption"&gt;Here, have a not very good looking sketch&lt;/label&gt;&lt;/p&gt;

&lt;p&gt;Due to the variable corner radius the hitbox logic needs to account for 2 distinct cases:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The radius is smaller than the corner: Here we need to create two extra rectangles to be subtracted from the "full" corner (square) geometry as the circle alone doesn't remove all we need&lt;/li&gt;&lt;li&gt;The radius is larger than the corner: Here we don't need need the extra rectangles, but we do need to make sure we position the circle correctly to be concentric with any potential screen corner radius.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
I also had to do some house keeping to get corner gestures to actually be registered because before this they were manually excluded, but for brevity's sake let's not go too deep into that.&lt;/p&gt;

&lt;h2&gt;I. don't. caaaareee!&lt;/h2&gt;

&lt;p&gt;
An interesting side note is that my changes initially didn't touch too many places in the KWin logic, but after discussing with KWin maintainers a bit we landed on wanting to change the logic of the &lt;code&gt;GestureRecognizer&lt;/code&gt;. Initially corner gestures were marked as having the &lt;code&gt;SwipeDirection&lt;/code&gt; &lt;b&gt;"DontCare"&lt;/b&gt; - this was needed because gesture recognition logic loops through all registered gestures and checks their conditions: Whether they require a specific start location and if so if the location matches and whether the direction of the user's swipe matches with what they expect.
This is great for all gestures KWin supported so far, but touch corner gestures - as mentioned before - need to be triggerable by any kind of movement; because they're in the corner they don't care which direction the finger moves (as long as it's still on the screen of course). Hence a new &lt;code&gt;SwipeDirection&lt;/code&gt;: "DontCare".&lt;/p&gt;

&lt;p&gt;I'll not bore you with the implementation details of why this wasn't ideal, but in the end I moved the old &lt;code&gt;SwipeDirection&lt;/code&gt; enum to a &lt;a href="https://doc.qt.io/qt-6/qflags.html"&gt;QFlags&lt;/a&gt; implementation - each direction gets its own location in a bit field and we can do flag based assignment. This means that for example the bottom left corner gesture now gets the direction &lt;code&gt;SwipeDirection::Up | SwipeDirection::Right&lt;/code&gt; set, which means &lt;i&gt;"I listen to both swipes that go upwards and ones that go to the right"&lt;/i&gt;. An interesting benefit of this is that this allows gestures in general to become multidirectional, not just corner gestures, but any of the other ones as well. Whether that actually has a practical use... We'll see in time, but it sure is interesting!&lt;/p&gt;

&lt;h1&gt;Limitations&lt;/h1&gt;

&lt;p&gt;
A new feature implementation wouldn't be complete without its own fun list of limitations. As this post is becoming quite long already let's do a quick short list:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We don't know the actual screen corner radius programmatically, so we just default to setting the radius to the corner radius. Yes, also for normal, non-rounded screens.&lt;/li&gt;&lt;li&gt;The corner radius is the same for all screens and all corners, so even if we knew the actual radius if it is not the same for all corners and all screens we're out of luck.&lt;/li&gt;&lt;li&gt;The corner gesture hitbox can overlap with UI elements making them impossible to tap on with a finger (mouse clicks are not affected). This is more of a theoretical issue as the geometry was chosen to be small enough to &lt;i&gt;mostly&lt;/i&gt; not interfere with UI elements &lt;img src="https://lprod.dev/blog/media/touch_corner_overlap.png" alt="This is the most overlap with an onscreen UI element corners will have by default"&gt;&lt;/img&gt;&lt;label class="media-caption"&gt;This is the most overlap with an onscreen UI element corners will have by default&lt;/label&gt;&lt;/li&gt;&lt;li&gt;Because of the corner radius being hard coded screens that have a radius larger than that will have mostly inaccessible touch corner gestures&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;/p&gt;

&lt;h1&gt;That's all, folks&lt;/h1&gt;

&lt;p&gt;
I think that about covers it - and I'm at just above half the word count from my last blog post! Just three more and I'll be at a reasonable length :))&lt;/p&gt;


&lt;/html&gt;
</description><guid isPermaLink="false">https://lprod.dev/blog/touch_corner_gestures.html</guid><pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate></item><item><title>Revamping Plasma Mobile Navigation Gestures</title><link>https://lprod.dev/blog/plasmo_nav_gestures.html</link><description>Down the rabbit hole

&lt;html&gt;
&lt;p&gt;A few months ago I was kind of toying with the idea to start contributing to Plasma Mobile because I was getting increasingly fed up with Android and I realized if Linux Mobile was going to be my daily driver before I need to buy a new phone I better help out.&lt;/p&gt;

&lt;p&gt;Then, after a few trivial commits I've seen that for the Plasma 6 release the navigation gestures were (at least temporarily) turned off - and since I am a &lt;b&gt;&lt;i&gt;very&lt;/i&gt;&lt;/b&gt; big fan of navigation gestures &lt;s&gt;because they are objectively the best way to interact with a phone&lt;/s&gt; I just couldn't have that and I went about fixing them.&lt;/p&gt;

&lt;h1&gt;A bit of context&lt;/h1&gt;

&lt;p&gt;
Why did the gestures even break by the upgrade to Plasma 6? Well, in Plasma Mobile 5 the navigation gestures were implemented in quite a hacky way - an invisible panel at the bottom screen edge that captured finger touches and handled the gesture and visual effect. While this worked this required a bunch of data moving around from KWin to the shell to show the window thumbnails which is unnecessary overhead.&lt;/p&gt;

&lt;p&gt;So for Plasma 6 Devin Lin rewrote the entire task switcher, including the navigation gestures, to be a KWin effect which should make it perform better and use more of its infrastructure to need less bespoke code.&lt;/p&gt;

&lt;p&gt;This went mostly quite smoothly, with few hiccups along the way. Unfortunately one of those hiccups was gestures (which now moved to KWin's &lt;code&gt;EffectTogglableTouchBorder&lt;/code&gt; interface) simply not working anymore.&lt;/p&gt;

&lt;h1&gt;Fixing gestures&lt;/h1&gt;

&lt;p&gt;
The &lt;a href="https://invent.kde.org/plasma/plasma-mobile/-/merge_requests/451/diffs"&gt;fix&lt;/a&gt; was surprisingly simple: In the constructor for setting up the task switcher, including all shortcuts and gestures for it, the &lt;code&gt;reconfigure&lt;/code&gt; function was simply never called which in turn meant the &lt;code&gt;KWin::EffectTogglableTouchBorder::setBorders&lt;/code&gt; function was never executed.
As you might imagine "setting the border" is quite a crucial part of having working gestures and one function call later gestures worked again!&lt;/p&gt;

&lt;h1&gt;Or did they&lt;/h1&gt;

&lt;p&gt;
&lt;i&gt;Disclaimer: I'm shuffling around the timeline a bit to make this post easier to follow, this part actually didn't happen until quite late.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;Turns out the gestures did work - but oddly enough only after opening the Action Drawer at least once after every screen geometry change (eg: screen rotation). But the Action Drawer doesn't have anything to do with the task switcher and its gestures, how did it have an effect on them?&lt;/p&gt;

&lt;p&gt;Well the reason is-... Honestly, I have no freaking clue. It makes no sense, but I also didn't really investigate it all that much, because I stumbled on the cause by accident quite quickly.&lt;/p&gt;

&lt;p&gt;It turns out that the KWin people have done a good job at making the &lt;code&gt;setBorders&lt;/code&gt; function quite safe to use and before reserving a touch border for an effect they first un-reserve anything that used to be on that border beforehand so two effects don't have to argue about who is allowed to react to the gesture.
The problem is that for some reason in the &lt;code&gt;reconfigure&lt;/code&gt; function in the task switcher effect logic &lt;i&gt;also&lt;/i&gt; unreserved and reserved the borders, kind of doing &lt;code&gt;setBorders&lt;/code&gt; job already before calling it.&lt;/p&gt;

&lt;p&gt;Now &lt;i&gt;why exactly&lt;/i&gt; that interfered with reserving the border I don't know, in theory &lt;code&gt;setBorders&lt;/code&gt; should unreserve our previous stupidity and set us up properly - but evidently it didn't and when I removed our unnecessary border shenanigans in &lt;code&gt;reconfigure&lt;/code&gt; suddenly gestures magically started working again. Either way, it's &lt;a href="https://invent.kde.org/plasma/plasma-mobile/-/merge_requests/487"&gt;fixed&lt;/a&gt; now.&lt;/p&gt;

&lt;h1&gt;But define "working"&lt;/h1&gt;

&lt;p&gt;
Well, it turns out that while KWin's border gesture infrastructure is quite nice, it also... doesn't allow customizing the distance a user needs to move their finger for a gesture to be "completed". It also turns out that on the PinePhone (and probably quite a few other phones) this lead to the gesture being... pretty much impossible to use. You just had to move your finger waaaaaayyyy too far (on the PinePhone about 3/4 of the screen height, see MR linked in next paragraph for video examples) to invoke the gesture. That's just unacceptable!&lt;/p&gt;

&lt;p&gt;Luckily the fix is quite easy and a &lt;a href="https://invent.kde.org/plasma/kwin/-/merge_requests/5336"&gt;quick MR&lt;/a&gt; to KWin allowed us to set custom gesture distances-... or so I thought.&lt;/p&gt;

&lt;p&gt;I mean, it did allow us to set the gesture distance, but that didn't mean the gestures were much better, so I went for another approach.&lt;/p&gt;

&lt;h1&gt;The rabbit hole.&lt;/h1&gt;

&lt;p&gt;
(&lt;i&gt;I'm talking about &lt;a href="https://invent.kde.org/plasma/plasma-mobile/-/merge_requests/454"&gt;this&lt;/a&gt; monster of an MR from here on out, it also contains a video example of the almost-final product&lt;/i&gt;)&lt;/p&gt;

&lt;p&gt;Ooooooh boy.&lt;/p&gt;

&lt;p&gt;I'll have you know that I have quite strong feelings towards what navigation gestures need to be able to do to be a nice user experience.&lt;/p&gt;

&lt;p&gt;One &lt;i&gt;very&lt;/i&gt; crucial part of this for me is being able to "flick away" an app and go to the homescreen. The old navigation gestures didn't support that - to go to the homescreen you needed to open the switcher, then tap on the side to close it. That's TWO WHOLE FINGER TAPS - UNACCEPTABLE (Well, one drag and one tap, but let's not be pedantic).&lt;/p&gt;

&lt;p&gt;And while we're at it, having "quick task switch" gestures would also be really nice - but I'll keep those for followup MRs, first I need to just revamp the task switcher backend to support tracking gesture velocity to discern between a drag with a pause at the end or a quick flick.&lt;/p&gt;

&lt;h2&gt;Velocity Tracking&lt;/h2&gt;

&lt;p&gt;
I'm gonna gloss over a lot of the details, but for a quick too-long-didn't-care-enough-to-write-it-all-down: KWin's gesture system doesn't expose gesture positions, just percentage based activation factors so I had to do some work to massage that into giving me the right data.&lt;/p&gt;

&lt;p&gt;After said massaging we now magically get the "primary" and "orthogonal" gesture position from KWin we can sit down to create velocity tracking&lt;/p&gt;

&lt;h3&gt;Moving average&lt;/h3&gt;

&lt;p&gt;
My first gut reaction was to implement a normal moving average calculation and after chatting a bit with Devin it seems other projects went for a similar approach. But then I looked at the moving average calculation in other places and... it looked so complicated and bloated and over the top to store all the past values and iterate through the entire list of them to average them out and doing all that every frame and ...&lt;/p&gt;

&lt;p&gt;As someone who initially learned programming by working with microcontrollers this was unacceptable (I see, this word is becoming a recurring theme). Now let's step back a bit and figure out what we &lt;i&gt;actually&lt;/i&gt; need. The moving average is just there to filter out spikes in movement speed, be it due to inaccurate sensor touch screen readings, frametime spikes or accidentally slipping with the finger.
We only want to filter, we do not actually care about receiving a mathematically accurate moving average. In fact we couldn't care less about getting a mathematically accurate moving average for our velocity.&lt;/p&gt;

&lt;h3&gt;We only want to filter&lt;/h3&gt;

&lt;p&gt;
Damn. Now if only someone knew how to choose and design filters.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Looks at Uni curriculum&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;Oh would you look at that! Signal theory, control technology and filter design this semester. I can finally procrastinate AND study for a course at the same time!&lt;/p&gt;

&lt;h3&gt;Exponentially Weighted Moving Average&lt;/h3&gt;

&lt;p&gt;
Even though I have a course on filter design at Uni, I never said I was any good at it. I mean, I'm okay enough, but not good enough to explain this filter better than &lt;a href="https://en.wikipedia.org/wiki/Exponential_smoothing"&gt;Wikipedia does&lt;/a&gt;.
The upshot of it is: It is a filter that does not need to store the entire history it tries to filter (&lt;i&gt;no ugly array of values to iterate through: check&lt;/i&gt;), it is essentially a low pass filter (&lt;i&gt;filters out transient spikes in movement speed: check&lt;/i&gt;) and it can be implemented in essentially 30 lines of code in a single function without any loops (&lt;i&gt;not overcomplicated and bloated: check&lt;/i&gt;).&lt;/p&gt;

&lt;p&gt;In fact, the EWMA filter is just a single formula that takes the previous filtered velocity, the current speed in the last time step (~frame) and a magic smoothing factor and spits out the filtered velocity updated with the newest sensor values. So that's just two lines for the actual filter (1 per axis) and some boilerplate. Neat!&lt;/p&gt;

&lt;h3&gt;Magic smoothing factor&lt;/h3&gt;

&lt;p&gt;
Usually you'd pick a smoothing factor based on the sampling rate of your system and your desired time constant. To emulate the behavior of moving averages I found elsewhere I picked a time constant of 30ms. This (very roughly) means, when starting from 0, a sudden input value is applied to the filter, it will reach ~63% of the input after 30ms - and after another 30ms it will have reached ~90%. This is roughly in line with an "proper" moving average with a window of 60-70ms.&lt;/p&gt;

&lt;p&gt;The problem we now have is that we don't have a fixed sampling interval - we get new gesture positions whenever KWin deems fit to give us some (which might be seconds apart if the user doesn't move the finger for a while). Sooooo what now? If we get a very long timescale our "roughly equivalent to a 60ms moving average" goes right out of the window.&lt;/p&gt;

&lt;p&gt;Well, luckily with one simple formula we can calculate our smoothing factor based on a desired time constant and a certain sampling interval which we can call every time we get a new value:&lt;/p&gt;

&lt;pre&gt;
smoothing_factor = 1 - exp(-delta_time/desired_time_constant)
&lt;/pre&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;(&lt;i&gt;Maybe someday I'll add a LaTeX parser to the blog. Or I just copy in a screenshot. We'll see&lt;/i&gt;)&lt;/p&gt;

&lt;p&gt;Now there is one remaining problem: As a self-respecting microcontroller dev who absolutely knows he is not restricted by a 16MHz CPU without a floating point arithmetic unit, but still cannot shake old habits that having &lt;code&gt;e&lt;/code&gt; to the power of a floating point number in that formula hurts.&lt;/p&gt;

&lt;p&gt;Luckily there is an approximation formula that is a bit cheaper&lt;/p&gt;

&lt;pre&gt;
smoothing_factor = delta_time/desired_time_constant
&lt;/pre&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;That approximation formula should only be used when the delta time is a lot smaller than the desired time constant, which we&lt;/p&gt;

&lt;p&gt;&lt;i&gt;checks notes&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;Oh. We don't really satisfy that condition. Eh. Whatever. We only need it to filter out super high weird spikes and be roughly in the right ballpark, we don't need to propulsively land a rocket.&lt;/p&gt;

&lt;p&gt;Some manual checks later show we'll not be all that far off the "correct" formula and we need to put a clamp on it anyways to always do &lt;i&gt;a bit&lt;/i&gt; of smoothing so we'd deviate from the right formula anyways.&lt;/p&gt;

&lt;p&gt;Do our "recalculate smoothing factor on every new value" shenanigans interfere with the stability or correctness of our filter? Probably, I dunno. But it's probably fine and throughout all of my testing, both throwing in arbitrary test values and empirical testing while using the gestures it all felt nice, so I give it my seal of approval!&lt;/p&gt;

&lt;p&gt;Now... where were we? Right!&lt;/p&gt;

&lt;h2&gt;Flick!&lt;/h2&gt;

&lt;p&gt;
And now with a simple check on &lt;code&gt;if speed &gt; threshold&lt;/code&gt; we can detect flicks! And voila - an upwards flick goes to homescreen!&lt;/p&gt;

&lt;p&gt;&lt;img src="https://lprod.dev/blog/media/nav_gestures_ready_for_review_1.jpg" alt=""&gt;&lt;/img&gt;&lt;/p&gt;

&lt;h2&gt;2D gestures&lt;/h2&gt;

&lt;p&gt;
Well, I know I said I'll replicate the old gesture behavior without touching any functionality and keep any extra features for followup MRs, but the gesture feels kinda bad when it only goes up and down and doesn't follow the finger left and right as well - and thanks to our previous excursion into KWin it also magically exposes the orthogonal gesture position, so we can just really quickly hook that up and have X and Y tracking.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://lprod.dev/blog/media/nav_gestures_ready_for_review_2.jpg" alt=""&gt;&lt;/img&gt;&lt;/p&gt;

&lt;h2&gt;States?!?!?!&lt;/h2&gt;

&lt;p&gt;
As a remnant from Devin's move to a KWin effect there was a bit of a mess of what keeps state where - he simply didn't have enough time to refactor the entire thing while also updating the rest of the shell to KF6 and all the fun API breakages and so there were several places that kept track of the same-ish state that made things confusing and hard to work with.&lt;/p&gt;

&lt;p&gt;No problem, I can refactor that and take some work off of Devin.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://lprod.dev/blog/media/nav_gestures_ready_for_review_3.jpg" alt=""&gt;&lt;/img&gt;&lt;/p&gt;

&lt;h2&gt;Quick task switch gesture&lt;/h2&gt;

&lt;p&gt;
But you know what, now the task switcher code feels really clean and nice and it would be so easy to just add a few lines of logic to discern between an upwards flick and a diagonal flick to switch to neighboring tasks.&lt;/p&gt;

&lt;p&gt;Ah to hell with it, let's add that as well!&lt;/p&gt;

&lt;p&gt;&lt;img src="https://lprod.dev/blog/media/nav_gestures_ready_for_review_4.jpg" alt=""&gt;&lt;/img&gt;&lt;/p&gt;

&lt;h2&gt;Task Scrub&lt;/h2&gt;

&lt;p&gt;
Remember how I said I have &lt;i&gt;opinions&lt;/i&gt; on what good gestures are?&lt;/p&gt;

&lt;p&gt;Well, I really really &lt;i&gt;really&lt;/i&gt; dislike what Android does with their task switcher where it uses some heuristic to only reorder the tasks based on recency after you have been in a task for a while. This allows you to use the quick task switch gesture several times in a row to go "further back" in the task history.&lt;/p&gt;

&lt;p&gt;But it's also kind of a black box as to when that happens and it really annoys me a lot - besides, the quick task switch gesture is neat for one switch, but gets very tiring to use when you have to use it several times in a row.&lt;/p&gt;

&lt;p&gt;So how about a bespoke "task scrub" gesture that activates on a mostly-horizontal gesture invocation and allows to scrub through a large number of recent tasks.&lt;/p&gt;

&lt;p&gt;&lt;img src="https://lprod.dev/blog/media/nav_gestures_ready_for_review_5.jpg" alt=""&gt;&lt;/img&gt;&lt;/p&gt;

&lt;h1&gt;Right.&lt;/h1&gt;

&lt;p&gt;
I've skipped over a lot of detail and some entire sidequests in this story (with a lot of potential for more jokes) for the sake of brevi-WOW HOW IS IT OVER 2000 WORDS ALREADY?!&lt;/p&gt;

&lt;p&gt;Uhm.&lt;/p&gt;

&lt;h1&gt;Wrapping Up&lt;/h1&gt;

&lt;p&gt;
There's still some bugs to fix, some tasks for later MRs (though much fewer than I thought there would be) and some decisions to make, but for now this has been my small odyssey about first fixing then slightly extending then completely rewriting the task switcher and navigation gestures for Plasma Mobil&lt;/p&gt;


&lt;/html&gt;
</description><guid isPermaLink="false">https://lprod.dev/blog/plasmo_nav_gestures.html</guid><pubDate>Sun, 05 May 2024 00:00:00 +0000</pubDate></item></channel></rss>